\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{blindtext}
\usepackage[a4paper, total={6in, 9.5in}]{geometry}
\usepackage{enumitem}


\title{

\begin{center} \textbf{Quant Curriculum Week 2}

Probability Theory and Statistics \end{center}
}

\author{Jonathan Qin}
\date{March 2, 2023}

\begin{document}

\maketitle

\section{Discrete and Continuous Distributions}

\subsection{Motivation}
We will begin by studying distribution functions widely used for quantitative modeling. Having a intuitive understanding of these functions and being able to discern the unique characteristics of a distribution is a valuable skill. 

\subsection{Definitions}
\begin{enumerate}
    \item Random Variable: can be discrete or continuous
    \item Cumulative distribution function: \(F(a) = P\{X \leq a\}\), \(\int_{-\infty}^{a} f(x) \,dx\)
    \item Probability mass function: \(p(x) = P\{X=x\}\) 
    \item Probability distribution function: \(f(x) = \frac{d}{dx}F(x)\)
    \item Expected value: \(E[X] = \sum_{x:p(x)>0} xp(x)\), \(\int_{-\infty}^{\infty} xf(x) \,dx\)
    \item Variance: \(var(X) = E[(X-E[X])^2] = E[X^2] - (E[X])^2\)
    \item Bernoulli trial: random experiment with two possible outcomes (success/failure) of consistent probability
\end{enumerate}

\subsection{Discrete / Continuous Random Variable Distributions}

\begin{enumerate}
    \item Uniform: probability distributions with equally likely outcomes
    \item Binomial (Discrete): probability distributions arising from several Bernoulli trials
    \item Normal (Gaussian): continuous probability distribution associated with the Central Limit Theorem (often used for natural and social sciences)
    \item Poisson (discrete): probability distribution expressing the probability of a given number of events occurring in a fixed interval of time given a known constant mean rate and independence
    \item Gamma: a family of distributions related to the beta, exponential, and chi-squared distributions
    \item Geometric (discrete): probability distribution of the number of Bernoulli trials to get one success  
    \item Exponential: probability distribution of the time between events in a Poisson point process
    \item Lognormal: random variables with the log being normally distributed
\end{enumerate}

\subsection{Moments of Distributions}
Moments of random variables describe quantitatively the shape of their distribution. For second and higher moments, the central moment (about the mean) is typically used to provide more meaningful information about the distribution's shape. If F is a cumulative probability distribution function, the n-th moment of the distribution is given by the Riemann-Stieltjes Integral:
\[\mu'(n) = E[X^n] = \int_{-\infty}^{\infty} x^n \,dF(x)\]
Furthermore, the Moment Generating Function is an alternative way to describe the distribution of a random variable. The Moment Generating Function of random variable \(X\), \(M_X(t)\), is given by:
\[ M_X(t) = E[e^{tX}] = \int_{-\infty}^{\infty} e^{tx} f(x) \,dx\]
The Moment Generating Function can be used to find the moments of a distribution, as \(M_X^(n)\) expanded becomes the series:
\[ M_X(t) = E[e^{tX}] = 1 + tE(X) + \frac{t^2E(X^2)}{2!} + \frac{t^3E(X^3)}{3!} + \cdots\]
Therefore, differentiating \(M_X(t)\) \(i\) times and setting \(t = 0\) will give the \(i\)th moment about the origin. A problem with moment-generating functions is that unlike characteristic functions (Fourier transform series), they may not exist for certain distributions, as the integral does not necessarily converge. However, it exists for almost all common distributions. 

\begin{enumerate}
    \item First Moment: Mean / Expected Value (raw moment)
    \item Second Moment: Variance, deviations from the mean (central moment)
    \item Third Moment: Skewness, a measure of the asymmetry of a distribution about the mean. Right skewed is defined as a positive skewness with the tail extending towards the right side. 
    \item Fourth Moment: Kurtosis, a measure of the thickness of tails. Excess kurtosis is kurtosis excess of the normal distribution. In finance, kurtosis is a measure of the extent of price fluctuations (how often prices move dramatically) and can be used to model risk in Value At Risk models.
\end{enumerate}

\paragraph{Example 1.1}
What is the moment-generating function of a standard normal distribution? What are the distribution's first, second, third, and fourth moments?
\newline
\newline

\end{document}